levels(sub_summary$error_discrete)<-seq(from=-180, to=180, by=20)
sub_summary$error_discrete<-as.numeric(as.character(sub_summary$error_discrete))
# estimated distributions
set6 <- data.frame(x6 = seq(from=-180,to=180,length.out=length(preds[[2]])),
y6 = preds[[2]]*(length(preds[[2]])/length(sub_summary[sub_summary$setsize == 6,]$error_discrete))
)
set3 <- data.frame(x3 = seq(from=-180,to=180,length.out=length(preds[[1]])),
y3 = preds[[1]]*(length(preds[[1]])/length(sub_summary[sub_summary$setsize == 3,]$error_discrete))
)
ggplot(sub_summary[sub_summary$setsize == 6,], aes(x = error_discrete, y = errors)) +
geom_line(aes(x = x3, y = y3), data = set3, lwd= 1) +
geom_line(aes(x = x6, y = y6), data = set6, lwd= 1, linetype = "dashed") +
geom_point(data = sub_summary[sub_summary$setsize == 6,], size = 4, pch=21, cex=1.5, col="black",bg="white") +
geom_point(data = sub_summary[sub_summary$setsize == 3,], size = 4, pch=21, cex=1.5, col="black",bg="grey") +
theme_bw() +
labs(title = "Zhang and Luck, 2008; Exp 2; Subject 1", x = "Difference in color value (degrees)", y = "Proportion of responses" ) +
scale_x_continuous(breaks=seq(-180, 180, 20))  # Ticks from 0-10, every .25
fit_mixture_model <- function(data, start_values) {
# placeholder for monte-carlo markov chain values
chain <- matrix(0,5000,2)
# put starting  values in first
chain[1,] <- start_values
# number of "burn-in" values
# aka. throw away the first N values
burnin <- 500
# proposed sd values
propsd <- start_values*.05
# upper and lower bounds
# c(prop in memory, degree error)
lb <- c(0,4)
ub <- c(1,360)
# number of iterations
N_chain <- dim(chain)[1]
for (i in c(2:N_chain)) {
cur <- chain[i-1,]
# Run loop until proposed values fall within upper and lower bounds
doitagain <- TRUE
while (doitagain) {
# proposed values + random noise
propl <- cur + rnorm(2,0,propsd)
doitagain <- any(propl<lb) || any(propl>ub)
}
# The use of logarithms guards against numerical issue that arise when very small (or large) numbers are multiplied
# one consequence: multiplication turns into addition
# likelihood of proposed values
lpropval <- logmixturepdf(data, propl[1], propl[2])
# likelihood of current values
lcurval  <- logmixturepdf(data,cur[1],cur[2])
# likelihood ratio
# Likewise, the ratio of the two values for the target distribution is computed by subtraction rather than division
# Because that ratio must be in the range 0-1 to permit comparison against a random uniform number,
# the difference operation on logarithms is exponentiated in the same line in order to return to the original untransformed space.
# (The exponentiated difference between two logs is the same as the ratio between the original numbers).
llratio  <- exp(lpropval-lcurval)
# if the value for the proposal is greater than for the current sample, then the ratio of values is necessarily greater than one
# thus the random uniform number can never be greater than the ratio and thus the proposal will always be accepted.
# When the ratio is less than 1,
if (runif(1) < llratio) {
chain[i,] <- propl
} else {
chain[i,] <- cur
}
}
# get final parameters
finparm <- apply(chain[-c(1:burnin),],2,mean)
#print(finparm)
td <- c(-180:180)
pred <- (1-finparm[1]) * dvonmises(mkcirc(td),mkcirc(0),sd2k(finparm[2])) + finparm[1]*rep(1,length(data))/(2*pi)
posterior<-chain[-c(1:burnin),]
return(list(preds=pred,posteriors=posterior))
}
sub_errors <- data %>%
filter(subject == 8,
setsize%in%c(3,6))
sub_summary  <- summary %>%
filter(subject == 8,
setsize%in%c(3,6))
#get predictions
start_values     <- c(0.5,20)
preds<-posteriors<- vector("list",2)
ssz              <- c(3, 6)
for (s in 1:length(ssz)) {
cp<-fit_mixture_model(subset(sub_errors,setsize==ssz[s])$errors,start_values)
preds[[s]] <- cp$preds
posteriors[[s]] <- cp$posterior
preds[[s]] <- preds[[s]]/sum(preds[[s]])  #normalize
}
sub_summary$setsize<-factor(sub_summary$setsize)
sub_summary$error_discrete<-factor(sub_summary$error_discrete)
levels(sub_summary$error_discrete)<-seq(from=-180, to=180, by=20)
sub_summary$error_discrete<-as.numeric(as.character(sub_summary$error_discrete))
# estimated distributions
set6 <- data.frame(x6 = seq(from=-180,to=180,length.out=length(preds[[2]])),
y6 = preds[[2]]*(length(preds[[2]])/length(sub_summary[sub_summary$setsize == 6,]$error_discrete))
)
set3 <- data.frame(x3 = seq(from=-180,to=180,length.out=length(preds[[1]])),
y3 = preds[[1]]*(length(preds[[1]])/length(sub_summary[sub_summary$setsize == 3,]$error_discrete))
)
ggplot(sub_summary[sub_summary$setsize == 6,], aes(x = error_discrete, y = errors)) +
geom_line(aes(x = x3, y = y3), data = set3, lwd= 1) +
geom_line(aes(x = x6, y = y6), data = set6, lwd= 1, linetype = "dashed") +
geom_point(data = sub_summary[sub_summary$setsize == 6,], size = 4, pch=21, cex=1.5, col="black",bg="white") +
geom_point(data = sub_summary[sub_summary$setsize == 3,], size = 4, pch=21, cex=1.5, col="black",bg="grey") +
theme_bw() +
labs(title = "Zhang and Luck, 2008; Exp 2; Subject 8", x = "Difference in color value (degrees)", y = "Proportion of responses" ) +
scale_x_continuous(breaks=seq(-180, 180, 20))  # Ticks from 0-10, every .25
#Load the CicStats package
library(CircStats)
#Define a customization of circ.mean{CircStats} that permits weighting observations
circ.weighted.mean = function (x,rho){
sinr = sum(rho*sin(x))
cosr = sum(rho*cos(x))
circmean = atan2(sinr, cosr)
return(circmean)
}
#Define a Customization of est.kappa{CircStats} that permits assuming a mean of zero
est_kappa = function (x, rho, mu ){
kappa = A1inv(sum(rho*cos(x-mu))/sum(rho))
return(kappa)
}
#Define a function to perform Expectation-Maximization
#   estimation of a uniform+VonMises mixture model
em_uvm = function( x , rho_start , do_mu , max_steps = 1e4 , max_reset = 1e3 , rel_tol=1.e-03 , trace = TRUE){
rho = rho_start
if(do_mu){
mu = circ.weighted.mean(x,rho)
}else{
mu = 0
}
kappa = est_kappa(x,rho,mu)
eps = Inf
last_NSLL = Inf
steps = 0
reset = 0
min_eps = eps
unif = dvm(0,0,0)
suppressWarnings(vm <- dvm(x,mu,kappa))
while (eps > rel_tol) {
if(steps>max_steps){
rel_tol = min_eps
kappa = kappa_start
rho = rho_start
eps = 1.0
steps = 0
}else{
rho = rho*vm/(rho*vm+(1-rho)*unif)
if(any(!is.finite(rho))){
if(reset<max_reset){
#try to reset the fit by re-starting at a random location
kappa = runif(1,0,exp(8))
mu = runif(1,0,2*pi)
rho = runif(1,0,1)
suppressWarnings(vm <- dvm(x,mu,kappa))
reset = reset+1
steps = 0
}else{
eps = -1
kappa = NA
rho =  NA
}
}else{
if(all(rho==0)){
rho = 0
kappa = NA
eps = -1
}else{
if(do_mu){
mu = circ.weighted.mean(x,rho)
}else{
mu = 0
}
kappa = est_kappa(x,rho,mu)
rho = mean(rho)
if(kappa<=0){
rho = 0
kappa = NA
eps = -1
}else{
steps = steps + 1
suppressWarnings(vm <- dvm(x,mu,kappa))
this_NSLL = -sum(log(rho*vm+(1-rho)*unif))
eps = last_NSLL-this_NSLL
min_eps = ifelse(eps<min_eps,eps,min_eps)
last_NSLL = this_NSLL
}
}
}
}
if(trace){
cat("trace:",steps,reset,rho,kappa,eps,"\n")
}
}
return(
list(
rho = rho
, kappa_prime = log(kappa)
, mu = ifelse(do_mu,mu,NA)
, rel_tol = rel_tol
, steps = steps
, reset = reset
)
)
}
#define some functions to help obtain an r-squared measure of fit
get_mix_density = function(x,rho,mu,kappa_prime){
suppressWarnings(dmixedvm(x,mu,0,exp(kappa_prime),0,rho))
}
get_mix_cdf = function(x,rho,mu,kappa_prime){
value = integrate(
get_mix_density
, lower = 0
, upper = x
, rho = rho
, mu = mu
, kappa_prime = kappa_prime
)$value
return(value)
}
get_rsq = function(x,rho,mu,kappa_prime){
x = sort(x)
n = length(x)
obs_p = (1:n)/n
exp_p = rep(NA,n)
for(i in 1:n){
exp_p[i]=get_mix_cdf(x[i],rho,mu,kappa_prime)
}
rsq = cor(obs_p,exp_p)^2
return(rsq)
}
#Define a function to run em_uvm2() across a range of
#   starting rho values
fit_uvm = function(data,do_mu){
rho_start = seq(.1,1,.1)
b = expand.grid(
rho_start = rho_start
, rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
, SLL = NA
)
for(i in 1:nrow(b)){
fit=NA
try(fit<-em_uvm(
data
, rho_start = b$rho_start[i]
, do_mu = do_mu
, trace = FALSE
)
, silent = TRUE
)
if(!is.list(fit)){
fit=list(
rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
)
}
b[i,2:7] = as.numeric(fit)
if(!is.na(fit$kappa_prime)){
suppressWarnings(b$SLL[i] <- sum(log(dmixedvm(data,0,0,exp(fit$kappa_prime),0,fit$rho))))
}else{
if(!is.na(fit$rho)){
b$SLL[i] = sum(log(dunif(data,0,2*pi)))
}
}
}
if(all(is.na(b$SLL))){
fit=list(
rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
, SLL = NA
, rsq = NA
)
}else{
fit = b[which.max(b$SLL),2:ncol(b)]
if(do_mu){
if(!is.na(fit$kappa_prime)){
fit$rsq = get_rsq(data,fit$rho,fit$mu,fit$kappa_prime)
}else{
fit$rsq = get_rsq(data,fit$rho,fit$mu,0)
}
}else{
if(!is.na(fit$kappa_prime)){
fit$rsq = get_rsq(data,fit$rho,0,fit$kappa_prime)
}else{
fit$rsq = get_rsq(data,fit$rho,0,0)
}
}
}
return(fit)
}
View(d)
n = 1
s = 3
s = 6
d <- data %>% filter(subject == n, setsize == s)
em_uvm(x = d$errors)
em_uvm(x = d$errors, rho_start = 0)
em_uvm(x = d$errors, rho_start = 0, do_mu = FALSE)
install.packages("CircStats")
#Load the CicStats package
library(CircStats)
#Define a customization of circ.mean{CircStats} that permits weighting observations
circ.weighted.mean = function (x,rho){
sinr = sum(rho*sin(x))
cosr = sum(rho*cos(x))
circmean = atan2(sinr, cosr)
return(circmean)
}
#Define a Customization of est.kappa{CircStats} that permits assuming a mean of zero
est_kappa = function (x, rho, mu ){
kappa = A1inv(sum(rho*cos(x-mu))/sum(rho))
return(kappa)
}
#Define a function to perform Expectation-Maximization
#   estimation of a uniform+VonMises mixture model
em_uvm = function( x , rho_start , do_mu , max_steps = 1e4 , max_reset = 1e3 , rel_tol=1.e-03 , trace = TRUE){
rho = rho_start
if(do_mu){
mu = circ.weighted.mean(x,rho)
}else{
mu = 0
}
kappa = est_kappa(x,rho,mu)
eps = Inf
last_NSLL = Inf
steps = 0
reset = 0
min_eps = eps
unif = dvm(0,0,0)
suppressWarnings(vm <- dvm(x,mu,kappa))
while (eps > rel_tol) {
if(steps>max_steps){
rel_tol = min_eps
kappa = kappa_start
rho = rho_start
eps = 1.0
steps = 0
}else{
rho = rho*vm/(rho*vm+(1-rho)*unif)
if(any(!is.finite(rho))){
if(reset<max_reset){
#try to reset the fit by re-starting at a random location
kappa = runif(1,0,exp(8))
mu = runif(1,0,2*pi)
rho = runif(1,0,1)
suppressWarnings(vm <- dvm(x,mu,kappa))
reset = reset+1
steps = 0
}else{
eps = -1
kappa = NA
rho =  NA
}
}else{
if(all(rho==0)){
rho = 0
kappa = NA
eps = -1
}else{
if(do_mu){
mu = circ.weighted.mean(x,rho)
}else{
mu = 0
}
kappa = est_kappa(x,rho,mu)
rho = mean(rho)
if(kappa<=0){
rho = 0
kappa = NA
eps = -1
}else{
steps = steps + 1
suppressWarnings(vm <- dvm(x,mu,kappa))
this_NSLL = -sum(log(rho*vm+(1-rho)*unif))
eps = last_NSLL-this_NSLL
min_eps = ifelse(eps<min_eps,eps,min_eps)
last_NSLL = this_NSLL
}
}
}
}
if(trace){
cat("trace:",steps,reset,rho,kappa,eps,"\n")
}
}
return(
list(
rho = rho
, kappa_prime = log(kappa)
, mu = ifelse(do_mu,mu,NA)
, rel_tol = rel_tol
, steps = steps
, reset = reset
)
)
}
#define some functions to help obtain an r-squared measure of fit
get_mix_density = function(x,rho,mu,kappa_prime){
suppressWarnings(dmixedvm(x,mu,0,exp(kappa_prime),0,rho))
}
get_mix_cdf = function(x,rho,mu,kappa_prime){
value = integrate(
get_mix_density
, lower = 0
, upper = x
, rho = rho
, mu = mu
, kappa_prime = kappa_prime
)$value
return(value)
}
get_rsq = function(x,rho,mu,kappa_prime){
x = sort(x)
n = length(x)
obs_p = (1:n)/n
exp_p = rep(NA,n)
for(i in 1:n){
exp_p[i]=get_mix_cdf(x[i],rho,mu,kappa_prime)
}
rsq = cor(obs_p,exp_p)^2
return(rsq)
}
#Define a function to run em_uvm2() across a range of
#   starting rho values
fit_uvm = function(data,do_mu){
rho_start = seq(.1,1,.1)
b = expand.grid(
rho_start = rho_start
, rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
, SLL = NA
)
for(i in 1:nrow(b)){
fit=NA
try(fit<-em_uvm(
data
, rho_start = b$rho_start[i]
, do_mu = do_mu
, trace = FALSE
)
, silent = TRUE
)
if(!is.list(fit)){
fit=list(
rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
)
}
b[i,2:7] = as.numeric(fit)
if(!is.na(fit$kappa_prime)){
suppressWarnings(b$SLL[i] <- sum(log(dmixedvm(data,0,0,exp(fit$kappa_prime),0,fit$rho))))
}else{
if(!is.na(fit$rho)){
b$SLL[i] = sum(log(dunif(data,0,2*pi)))
}
}
}
if(all(is.na(b$SLL))){
fit=list(
rho = NA
, kappa_prime = NA
, mu = NA
, rel_tol = NA
, steps = NA
, reset = NA
, SLL = NA
, rsq = NA
)
}else{
fit = b[which.max(b$SLL),2:ncol(b)]
if(do_mu){
if(!is.na(fit$kappa_prime)){
fit$rsq = get_rsq(data,fit$rho,fit$mu,fit$kappa_prime)
}else{
fit$rsq = get_rsq(data,fit$rho,fit$mu,0)
}
}else{
if(!is.na(fit$kappa_prime)){
fit$rsq = get_rsq(data,fit$rho,0,fit$kappa_prime)
}else{
fit$rsq = get_rsq(data,fit$rho,0,0)
}
}
}
return(fit)
}
em_uvm(x = d$errors, rho_start = 0, do_mu = 0)
em_uvm(x = d$errors, rho_start = 0, do_mu = FALSE)
test<-em_uvm(x = d$errors, rho_start = 0, do_mu = FALSE)
View(test)
test<-fit_uvm(data = d$errors, do_mu = 0)
test<-fit_uvm(data = d$errors, do_mu = TRUE)
test<-fit_uvm(data = d$errors, do_mu = FALSE)
